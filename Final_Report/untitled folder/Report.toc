\contentsline {section}{\numberline {1}Abstract}{4}{}%
\contentsline {section}{\numberline {2}Introduction}{9}{}%
\contentsline {subsection}{\numberline {2.1}Motivation}{9}{}%
\contentsline {subsection}{\numberline {2.2}Current Systems}{9}{}%
\contentsline {subsection}{\numberline {2.3}Problems with Current Systems}{10}{}%
\contentsline {subsection}{\numberline {2.4}Reinforcement Learning System}{10}{}%
\contentsline {section}{\numberline {3}Background}{11}{}%
\contentsline {subsection}{\numberline {3.1}EE303 Mobile Robotics}{11}{}%
\contentsline {subsection}{\numberline {3.2}Reinforcement learning}{12}{}%
\contentsline {subsection}{\numberline {3.3}Reinforcement learning Algorythms}{14}{}%
\contentsline {subsubsection}{\numberline {3.3.1}PPO}{14}{}%
\contentsline {subsubsection}{\numberline {3.3.2}DQN}{14}{}%
\contentsline {subsection}{\numberline {3.4}Problem}{14}{}%
\contentsline {subsection}{\numberline {3.5}Related Work}{15}{}%
\contentsline {section}{\numberline {4}Design}{15}{}%
\contentsline {subsection}{\numberline {4.1}Choosing Python Physics Engine}{15}{}%
\contentsline {subsection}{\numberline {4.2}PyBullet}{15}{}%
\contentsline {subsubsection}{\numberline {4.2.1}Advantages}{16}{}%
\contentsline {subsubsection}{\numberline {4.2.2}Disadvantages}{16}{}%
\contentsline {subsection}{\numberline {4.3}PyGame}{16}{}%
\contentsline {subsubsection}{\numberline {4.3.1}Advantages}{17}{}%
\contentsline {subsubsection}{\numberline {4.3.2}Disadvantages}{17}{}%
\contentsline {subsection}{\numberline {4.4}Differential Drive Function}{18}{}%
\contentsline {subsection}{\numberline {4.5}Collision Detection}{19}{}%
\contentsline {subsection}{\numberline {4.6}Action Space}{21}{}%
\contentsline {subsection}{\numberline {4.7}Observation Space}{21}{}%
\contentsline {subsubsection}{\numberline {4.7.1}Initial Observation Space}{22}{}%
\contentsline {subsubsection}{\numberline {4.7.2}Simplified Observation Space}{23}{}%
\contentsline {subsubsection}{\numberline {4.7.3}Final Observation Space}{24}{}%
\contentsline {subsection}{\numberline {4.8}Reward Function}{25}{}%
\contentsline {subsubsection}{\numberline {4.8.1}Initial Reward System}{25}{}%
\contentsline {subsubsection}{\numberline {4.8.2}Further Reward System}{25}{}%
\contentsline {subsubsection}{\numberline {4.8.3}Final Reward System}{26}{}%
\contentsline {subsection}{\numberline {4.9}Choosing RL Algorythm}{26}{}%
\contentsline {subsection}{\numberline {4.10}Training}{26}{}%
\contentsline {subsubsection}{\numberline {4.10.1}Process}{27}{}%
\contentsline {subsubsection}{\numberline {4.10.2}TensorBoard}{27}{}%
\contentsline {subsection}{\numberline {4.11}Porting to Hardware}{28}{}%
\contentsline {subsubsection}{\numberline {4.11.1}Exporting Neural Network}{28}{}%
\contentsline {subsubsection}{\numberline {4.11.2}Programming Microcontroller}{30}{}%
\contentsline {subsubsection}{\numberline {4.11.3}Integration Issues}{30}{}%
\contentsline {section}{\numberline {5}Testing}{31}{}%
\contentsline {subsection}{\numberline {5.1}Simulator}{31}{}%
\contentsline {subsubsection}{\numberline {5.1.1}Debugging Observations Space}{31}{}%
\contentsline {subsubsection}{\numberline {5.1.2}Debugging Action Space}{31}{}%
\contentsline {subsubsection}{\numberline {5.1.3}Debugging Reward Function}{31}{}%
\contentsline {subsection}{\numberline {5.2}Hardware}{31}{}%
\contentsline {subsubsection}{\numberline {5.2.1}Integrations Issues}{31}{}%
\contentsline {section}{\numberline {6}Results}{31}{}%
\contentsline {subsection}{\numberline {6.1}Simulator Performance}{31}{}%
\contentsline {subsection}{\numberline {6.2}Hardware Performance}{31}{}%
\contentsline {section}{\numberline {7}Conclusion}{31}{}%
